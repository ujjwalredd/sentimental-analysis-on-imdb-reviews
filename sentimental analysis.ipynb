{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7fc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/train/pos\"  \n",
    "content_list = []\n",
    "\n",
    "# collecting all the data from each file and adding them into a list called content_list for pos txt\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            \n",
    "            with open(file_path, 'r') as text_file:\n",
    "                content = text_file.read()\n",
    "                \n",
    "            content_list.append(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25435ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list.insert(0,\"Sentiment\") # inserting the first value of list as Sentiment because it will be useful while creating the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8570a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/train/neg\"  \n",
    "\n",
    "neg = []\n",
    "\n",
    "# collecting all the data from each file and adding them into a list called content_list for neg txt\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            \n",
    "            with open(file_path, 'r') as text_file:\n",
    "                content = text_file.read()\n",
    "                \n",
    "            neg.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b781d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/train/unsup\"  \n",
    "unsup = []\n",
    "\n",
    "# collecting all the data from each file and adding them into a list called content_list for unsup txt\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            \n",
    "            with open(file_path, 'r') as text_file:\n",
    "                content = text_file.read()\n",
    "                \n",
    "            unsup.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b60173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/Users/ujjwalreddyks/Desktop/output.csv' has been created with the content.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_path = \"/Users/ujjwalreddyks/Desktop/output.csv\"\n",
    "\n",
    "\n",
    "#in this we create the csv file using the content_list \n",
    "\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "\n",
    "    for row in content_list:\n",
    "        csv_writer.writerow([row])\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' has been created with the content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ec298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/ujjwalreddyks/Desktop/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a422773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentiment\n",
       "0  For a movie that gets no respect there sure ar...\n",
       "1  Bizarre horror movie filled with famous faces ...\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...\n",
       "3  It's a strange feeling to sit alone in a theat...\n",
       "4  You probably all already know this by now, but..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e568541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = 'pos' # give labels values of content_list whiich are pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f645f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#we append the neg values intot the csv file\n",
    "neg_df = pd.DataFrame({'Sentiment': neg})\n",
    "\n",
    "result_df = pd.concat([df, neg_df], ignore_index=True)\n",
    "\n",
    "#we append the unsup values intot the csv file\n",
    "\n",
    "unsup_df = pd.DataFrame({'Sentiment': unsup})\n",
    "\n",
    "result_df1 = pd.concat([result_df, unsup_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed44b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['labels'].fillna('neg', inplace=True) # give labels values of neg whiich are negative\n",
    "result_df1['labels'].fillna('unsup', inplace=True) # give labels values of neg whiich are unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eb6b5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>I'll keep this short. &lt;br /&gt;&lt;br /&gt;Most of what...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>I absolutely love this show. I stumbled upon i...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>Ohh my God, I actually went out and bought thi...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>Angels and Insects is a thoughtful adult tale ...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>This is the greatest scripted, live action com...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentiment labels\n",
       "0      For a movie that gets no respect there sure ar...    pos\n",
       "1      Bizarre horror movie filled with famous faces ...    pos\n",
       "2      A solid, if unremarkable film. Matthau, as Ein...    pos\n",
       "3      It's a strange feeling to sit alone in a theat...    pos\n",
       "4      You probably all already know this by now, but...    pos\n",
       "...                                                  ...    ...\n",
       "74995  I'll keep this short. <br /><br />Most of what...  unsup\n",
       "74996  I absolutely love this show. I stumbled upon i...  unsup\n",
       "74997  Ohh my God, I actually went out and bought thi...  unsup\n",
       "74998  Angels and Insects is a thoughtful adult tale ...  unsup\n",
       "74999  This is the greatest scripted, live action com...  unsup\n",
       "\n",
       "[75000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4859e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df1.to_csv(\"/Users/ujjwalreddyks/Desktop/train.csv\", index=False) #saving the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee28c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# collecting all the data from each file and adding them into a list called content_list for pos txt for test \n",
    "folder_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/test/pos\"  \n",
    "test_pos = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            \n",
    "            with open(file_path, 'r') as text_file:\n",
    "                content = text_file.read()\n",
    "                \n",
    "            test_pos.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "416ad2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos.insert(0, 'Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ed32dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/test/neg\"  \n",
    "test_neg = []\n",
    "# collecting all the data from each file and adding them into a list called content_list for pos txt for test \n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            \n",
    "            with open(file_path, 'r') as text_file:\n",
    "                content = text_file.read()\n",
    "                \n",
    "            test_neg.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb56d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/Users/ujjwalreddyks/Desktop/output.csv' has been created with the content.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_path = \"/Users/ujjwalreddyks/Desktop/output.csv\"\n",
    "\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "\n",
    "    for row in test_pos:\n",
    "        csv_writer.writerow([row])\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' has been created with the content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2aef322",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv(\"/Users/ujjwalreddyks/Desktop/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aad2c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['labels'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af6b6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_dff = pd.DataFrame({'Sentiment': neg})\n",
    "\n",
    "result_test = pd.concat([dft, neg_dff], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e11a5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test['labels'].fillna('neg', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24e6cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test.to_csv(\"/Users/ujjwalreddyks/Desktop/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c39ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ujjwalreddyks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ujjwalreddyks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to '/Users/ujjwalreddyks/Downloads/aclImdb/train_final.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "#cleaning the sentiment texts for better traning of the model \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "csv_file_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/train.csv\"  \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Joining the cleaned words back into text\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "df['clean_sentiment'] = df['Sentiment'].apply(clean_text)\n",
    "\n",
    "\n",
    "output_csv_file_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/train_final.csv\" \n",
    "df.to_csv(output_csv_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to '{output_csv_file_path}'.\") # saves as train_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "137919b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ujjwalreddyks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ujjwalreddyks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to '/Users/ujjwalreddyks/Downloads/aclImdb/test_final.csv'.\n"
     ]
    }
   ],
   "source": [
    "#cleaning the sentiment texts for better testing of the model \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "csv_file_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/test.csv\"  \n",
    "dff = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Joining the cleaned words back into text\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "dff['clean_sentiment'] = dff['Sentiment'].apply(clean_text)\n",
    "\n",
    "\n",
    "output_csv_file_path = \"/Users/ujjwalreddyks/Downloads/aclImdb/test_final.csv\" \n",
    "dff.to_csv(output_csv_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to '{output_csv_file_path}'.\") # saves as test_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bff2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "train_final = pd.read_csv(\"/Users/ujjwalreddyks/Downloads/aclImdb/train_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b040ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.read_csv(\"/Users/ujjwalreddyks/Downloads/aclImdb/test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4f757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_final[train_final['labels'] != 'unsup'] # i tried traning the model without removing unsup there was error while finding acuracy so need to remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfbf3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labels</th>\n",
       "      <th>clean_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>pos</td>\n",
       "      <td>movie gets respect sure lot memorable quotes l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>bizarre horror movie filled famous faces stole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>pos</td>\n",
       "      <td>solid unremarkable film matthau einstein wonde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>pos</td>\n",
       "      <td>strange feeling sit alone theater occupied par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>pos</td>\n",
       "      <td>probably already know 5 additional episodes ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>My comments may be a bit of a spoiler, for wha...</td>\n",
       "      <td>neg</td>\n",
       "      <td>comments may bit spoiler worth stop care enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>The \"saucy\" misadventures of four au pairs who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>saucy misadventures four au pairs arrive londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Oh, those Italians! Assuming that movies about...</td>\n",
       "      <td>neg</td>\n",
       "      <td>oh italians assuming movies aristocrats weird ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Eight academy nominations? It's beyond belief....</td>\n",
       "      <td>neg</td>\n",
       "      <td>eight academy nominations beyond belief think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Not that I dislike childrens movies, but this ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>dislike childrens movies tearjerker redeeming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentiment labels  \\\n",
       "0      For a movie that gets no respect there sure ar...    pos   \n",
       "1      Bizarre horror movie filled with famous faces ...    pos   \n",
       "2      A solid, if unremarkable film. Matthau, as Ein...    pos   \n",
       "3      It's a strange feeling to sit alone in a theat...    pos   \n",
       "4      You probably all already know this by now, but...    pos   \n",
       "...                                                  ...    ...   \n",
       "24995  My comments may be a bit of a spoiler, for wha...    neg   \n",
       "24996  The \"saucy\" misadventures of four au pairs who...    neg   \n",
       "24997  Oh, those Italians! Assuming that movies about...    neg   \n",
       "24998  Eight academy nominations? It's beyond belief....    neg   \n",
       "24999  Not that I dislike childrens movies, but this ...    neg   \n",
       "\n",
       "                                         clean_sentiment  \n",
       "0      movie gets respect sure lot memorable quotes l...  \n",
       "1      bizarre horror movie filled famous faces stole...  \n",
       "2      solid unremarkable film matthau einstein wonde...  \n",
       "3      strange feeling sit alone theater occupied par...  \n",
       "4      probably already know 5 additional episodes ne...  \n",
       "...                                                  ...  \n",
       "24995  comments may bit spoiler worth stop care enoug...  \n",
       "24996  saucy misadventures four au pairs arrive londo...  \n",
       "24997  oh italians assuming movies aristocrats weird ...  \n",
       "24998  eight academy nominations beyond belief think ...  \n",
       "24999  dislike childrens movies tearjerker redeeming ...  \n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9d4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features\n",
    "\n",
    "X_train = tfidf_vectorizer.fit_transform(train_final['clean_sentiment'])\n",
    "X_test = tfidf_vectorizer.transform(test_final['clean_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051fe7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\"pos\": 1, \"neg\": 0}\n",
    "\n",
    "train_final['labels'] = train_final['labels'].map(label_mapping) #giving values to train label values \n",
    "test_final['labels'] = test_final['labels'].map(label_mapping) #giving values to test label values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286d53d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, train_final['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "211b5d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.91344\n",
      "Random Forest Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     12500\n",
      "           1       1.00      0.83      0.91     12500\n",
      "\n",
      "    accuracy                           0.91     25000\n",
      "   macro avg       0.93      0.91      0.91     25000\n",
      "weighted avg       0.93      0.91      0.91     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(train_final['labels'], y_pred_rf)\n",
    "report_rf = classification_report(test_final['labels'], y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Model Accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest Model Classification Report:\\n\", report_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48cef7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This is a positive review.\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I didn't like this product.\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"This is a positive review.\", \"I didn't like this product.\"]\n",
    "X_new = tfidf_vectorizer.transform(new_text)\n",
    "\n",
    "# Make predictions using the trained Random Forest model\n",
    "predictions = rf_model.predict(X_new)\n",
    "\n",
    "# Print the predictions\n",
    "for text, prediction in zip(new_text, predictions):\n",
    "    sentiment = \"Positive\" if prediction == \"pos\" else \"Negative\"\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c79af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
